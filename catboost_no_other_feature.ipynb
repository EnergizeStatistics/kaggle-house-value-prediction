{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zillow's Home Value Prediction (Zestimate) #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "                                   \n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/lee/Documents/Datasets for GitHub/kaggle_zillow_home_value_prediction/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_no_hash_labeled_train = pd.read_pickle(data_dir+'X_no_hash_labeled_train.pkl')\n",
    "X_no_hash_labeled_val = pd.read_pickle(data_dir+'X_no_hash_labeled_val.pkl')\n",
    "y_labeled_train = pd.read_pickle(data_dir+'y_labeled_train.pkl')\n",
    "y_labeled_val = pd.read_pickle(data_dir+'y_labeled_val.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_all_rm_miss = tuple(X_no_hash_labeled_train)\n",
    "\n",
    "flag_features_set = set(('fireplaceflag', 'hashottuborspa', 'pooltypeid10', 'pooltypeid2', 'pooltypeid7', \\\n",
    "                         'taxdelinquencyflag'))\n",
    "\n",
    "categorical_features_set = set(('airconditioningtypeid', 'architecturalstyletypeid', \\\n",
    "                                'buildingclasstypeid', 'decktypeid', 'fips', 'heatingorsystemtypeid', \\\n",
    "                                'propertycountylandusecode', 'propertylandusetypeid', \\\n",
    "                                'propertyzoningdesc', 'rawcensustractandblock', 'censustractandblock', \\\n",
    "                                'regionidcounty', 'regionidcity', 'regionidzip', \\\n",
    "                                'regionidneighborhood', 'typeconstructiontypeid', 'assessmentyear', \\\n",
    "                                'taxdelinquencyyear', 'transaction_year', 'transaction_month'))\n",
    "\n",
    "categorical_features_index_rm_miss = list(icol for icol, col in enumerate(columns_all_rm_miss) \\\n",
    "                                          if (col in categorical_features_set) == True)\n",
    "\n",
    "categorical_features_names_rm_miss = tuple(col for col in columns_all_rm_miss \\\n",
    "                                           if (col in categorical_features_set) == True)\n",
    "\n",
    "# del flag_features_set, continuous_features_set, categorical_features_set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize Pool\n",
    "train_pool = Pool(X_no_hash_labeled_train, label=y_labeled_train, cat_features=categorical_features_index_rm_miss)\n",
    "val_pool = Pool(X_no_hash_labeled_val, cat_features=categorical_features_index_rm_miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_catboost = CatBoostRegressor(loss_function='MAE', eval_metric='MAE', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "reg_catboost.fit(train_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE in training: 0.06544938\n",
      "MAE in validation: 0.06836046\n"
     ]
    }
   ],
   "source": [
    "# make the prediction using the resulting model\n",
    "print(\"MAE in training: {:.8f}\".format(mean_absolute_error(y_labeled_train, reg_catboost.predict(train_pool))))\n",
    "print(\"MAE in validation: {:.8f}\".format(mean_absolute_error(y_labeled_val, reg_catboost.predict(val_pool))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters are: {'depth': 6, 'l2_leaf_reg': 4, 'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"learning_rate\": [0.01, 0.03, 0.1],\n",
    "              \"depth\": [3, 6, 9],\n",
    "              \"l2_leaf_reg\": [1, 4, 9]\n",
    "             }\n",
    "\n",
    "# run search\n",
    "reg_catboost_cv = CatBoostRegressor(loss_function='MAE', eval_metric='MAE', verbose=False)\n",
    "random_search = GridSearchCV(reg_catboost_cv, param_dist, scoring=\"neg_mean_absolute_error\", cv = 3)\n",
    "\n",
    "random_search.fit(X_no_hash_labeled_train, y_labeled_train, cat_features=categorical_features_index_rm_miss)\n",
    "\n",
    "print(\"Best hyperparameters are: {}\".format(random_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE in training: 0.06583512\n",
      "MAE in validation: 0.06818038\n"
     ]
    }
   ],
   "source": [
    "reg_catboost_cv = CatBoostRegressor(loss_function='MAE', eval_metric='MAE', verbose=False, **random_search.best_params_)\n",
    "reg_catboost_cv.fit(train_pool)\n",
    "# make the prediction using the resulting model\n",
    "print(\"MAE in training: {:.8f}\".format(mean_absolute_error(y_labeled_train, reg_catboost_cv.predict(train_pool))))\n",
    "print(\"MAE in validation: {:.8f}\".format(mean_absolute_error(y_labeled_val, reg_catboost_cv.predict(val_pool))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Submission File ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lee/.local/lib/python3.6/site-packages/numpy/lib/arraysetops.py:518: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(data_dir+'sample_submission.csv', header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission_prediction(year, month, reg_name, x_test):\n",
    "    y_pred = pd.DataFrame(reg_name.predict(x_test), index=sample_submission.index, columns=[str(year)+str(month)])\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in (2016, 2017):\n",
    "    for month in (10, 11, 12):\n",
    "        orig = pd.read_pickle(data_dir+eval(\"'X_no_hash_test_\" + str(year) + str(month) + \".pkl'\"))\n",
    "        # above evaluates to:\n",
    "        # orig = pd.read_pickle(data_dir+'X_no_hash_test_201610\".pkl')\n",
    "\n",
    "        # initialize Pool\n",
    "        orig[list(categorical_features_names_rm_miss)] = orig[list(categorical_features_names_rm_miss)].astype(str)\n",
    "\n",
    "        test_pool = Pool(orig, cat_features=categorical_features_index_rm_miss)\n",
    "\n",
    "        exec(\"y_pred\" + str(year) + str(month) + \" = make_submission_prediction(\" + str(year) +\", \" + str(month) \\\n",
    "             + \", reg_catboost_cv, test_pool\" + \")\")\n",
    "        # above evaluates to:\n",
    "        # y_pred201610 = make_submission_prediction(2016, 10, reg_catboost_cv, test_pool)\n",
    "        \n",
    "        exec(\"sample_submission.update(y_pred\" + str(year) + str(month) + \")\")\n",
    "\n",
    "        pred = eval(\"y_pred\" + str(year) + str(month))\n",
    "        \n",
    "        del orig, test_pool, pred\n",
    "        \n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(data_dir+'CatBoost_no_hash_submit_to_kaggle.csv', float_format='%.4f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
